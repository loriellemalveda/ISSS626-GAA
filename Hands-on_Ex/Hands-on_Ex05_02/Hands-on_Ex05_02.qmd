---
title: "Hands-on Exercise 5 - Part 2: Local Measures of Spatial Autocorrelation"
author: "Lorielle Malveda"
date: "September 23, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  freeze: true
  warning: false
---

# 1. OVERVIEW

**Local Measures of Spatial Autocorrelation (LMSA)** analyze the relationships between each observation and its surroundings, offering detailed insights into the spatial structure of data rather than providing a global summary. These measures are not mere summary statistics; they are specific scores that reveal the spatial dynamics within the dataset. Often, these local measures are related to their global counterparts, sometimes being components that together form the global statistic. For example, Local Indicators of Spatial Association (LISA) are directly linked to broader global metrics and can be seen as their disaggregated form. Another local measure, the **Getis-Ord’s Gi-statistics**, offers complementary perspectives or similar insights for data with geographical references.

In this practical exercise, you will learn to compute various Local Measures of Spatial Autocorrelation using the `spdep` package.

By the end of this session, you will be able to:

-   Import geospatial data using the relevant functions from the `sf` package,
-   Load a CSV file using the `readr` package,
-   Perform relational joins using the appropriate functions from the `dplyr` package,
-   Calculate Local Indicator of Spatial Association (LISA) statistics to identify clusters and outliers using the `spdep` package,
-   Determine hot spots and cold spots using Getis-Ord’s Gi-statistics with the `spdep` package, and
-   Visualize your analysis results using the `tmap` package.

# 2. GETTING STARTED

## 2.1 Objective - The Analytical Question

In spatial policy, a key development goal for local governments and planners is to ensure an equal distribution of development across the province.

The objective of this study is to apply appropriate spatial statistical methods to determine whether development is distributed geographically. If it is not, the next step is to investigate whether there is evidence of spatial clustering. If clustering is present, we will then seek to identify the locations of these clusters.

In this case study, we focus on analyzing the spatial pattern of a specific development indicator—GDP per capita—in Hunan Province, People's Republic of China.

## 2.2 Study Area and Dataset

Two data sets will be used in this hands-on exercise, which are:

1.  **Hunan Province Administrative Boundary Layer (at County Level).** This is a geospatial data set in ESRI shapefile format.
2.  **Hunan_2012.csv.** This csv file contains selected Hunan’s local development indicators in 2012.

## 2.3 Setting the Analytical Tools

This code chunk uses `p_load()` of the ***pacman*** package (stands for Package Manager) to check if the following packages are installed:

**sf:** used for importing and handling geospatial data in R.

**tidyverse:** mainly used for wrangling attribute data in R.

***spdep:*** used to compute spatial weights, global and local spatial autocorrelation statistics.

**tmap:** used to prepare cartographic quality chropleth map.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse)
```

If available, the packages will then be launched into R.

# 3. GETTING THE DATA INTO R ENVIRONMENT

In this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.

## 3.1 Importing *shapefile* into the R Environment

Let us use the ***sf*** package to import the Hunan shapefile into R.

The output is a simple features ***sf*** object.

```{r}
hunan <- st_read(dsn = "data/geospatial",                   layer = "Hunan")
```

## 3.2 Importing *csv* into the R Environment

Next, we will import `Hunan_2012.csv` into R by using the `read_csv` function of the ***readr*** package.

The output is R dataframe class.

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

## 3.3 Performing Relational Join

The following code chunk updates the attribute table of the `hunan` SpatialPolygonsDataFrame by merging it with the attribute fields of the `hunan2012` dataframe. This is accomplished using the `left_join()` function from the `dplyr` package:

```{r}
hunan <- left_join(hunan,hunan2012) %>%
  select(1:4, 7, 15)
```

## 3.4 Visualizing the Regional Development Indicator

Next, we'll prepare a basemap and a choropleth map to display the distribution of GDP per capita for 2012, using the `qtm()` function from the `tmap` package.

```{r}
equal <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(hunan) +
  tm_fill("GDPPC",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

# 4. LOCAL INDICATORS OF SPATIAL ASSOCIATION (LISA)

**Local Indicators of Spatial Association or LISA** are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of GDP per capita of Hunan Provice, People Republic of China, local clusters in GDP per capita mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

In this section, you will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’s I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.

## 4.1 Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct **a spatial weights matrix f**or the study area. This matrix defines the neighborhood relationships between the geographical units (e.g., counties) in the study area.

In the code below, the `poly2nb()` function from the `spdep` package is used to compute contiguity weight matrices. This function creates a neighbors list based on regions that share contiguous boundaries. According to the documentation, you can specify the "queen" argument, which takes either `TRUE` or `FALSE`. If you do not specify this argument, the default is `TRUE`, meaning that the function will return a list of first-order neighbors based on the Queen contiguity criteria unless you explicitly set `queen = FALSE`.

The following code chunk specifically computes the Queen contiguity weight matrix.

```{r}
wm_q <- poly2nb(hunan, 
                queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.

## 4.2 Row-standardized Weights Matrix

Next, we need to assign weights to each neighboring polygon. In our case, we will assign equal weights to each neighboring polygon (style = "W"). This is done by assigning the fraction 1 / (# of neighbors) to each neighboring county and then summing the weighted values, such as income. **While this method is intuitive, it has a potential drawback: polygons located at the edges of the study area will have fewer neighbors, which could lead to over- or under-estimating the true extent of spatial autocorrelation in the data.**

For simplicity, we will use the style = "W" option in this example. However, it’s worth noting that other more robust options are available, such as style = "B", which might address some of these limitations.

```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

The code chunk above demonstrates the use of the `nb2listw()` function, which converts a neighbors list object of class `nb` into a spatial weights list. There are two key arguments in this function: `style` and `zero.policy`.

-   The input of [`nb2listw()`](https://r-spatial.github.io/spdep/reference/nb2listw.html) must be an object of class **nb**. The syntax of the function has two major arguments, namely style and zero.poly.

-   *style* can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).

-   If *zero policy* is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.

## 4.3 Computing Local Moran's I

To calculate local Moran’s I, the `localmoran()` function from the `spdep` package is used. This function analyzes local spatial autocorrelation using `zi` values (like GDP per capita for counties) and a `listw` object for neighbor weighting.

The code provided specifically calculates local Moran’s I for GDP per capita in 2012 at the county level, identifying areas where GDP per capita is significantly clustered or dispersed among neighboring counties.

```{r}
fips <- order(hunan$County)
localMI <- localmoran(hunan$GDPPC, rswm_q)
head(localMI)
```

*The* `localmoran()` function returns a matrix of values whose columns are:

-   **Ii:** the local Moran’s I statistics

-   **E.Ii:** the expectation of the local Moran statistic under the randomization hypothesis

-   **Var.Ii:** the variance of the local Moran statistic under the randomization hypothesis

-   **Z.Ii:** the standard deviation of the local Moran statistic

-   **Pr():** the p-value of the local Moran statistic

The code chunk below lists the content of the local Moran matrix derived by using `printCoefmat()`.

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=hunan$County[fips]),
  check.names=FALSE)
```

### MAPPING THE LOCAL MORAN'S I

Before creating a map of local Moran’s I, it's practical to merge the local Moran’s I data frame (referred to as `localMI`) with the `hunan` SpatialPolygonDataFrame. The following code snippets facilitate this task, resulting in a new SpatialPolygonDataFrame named `hunan.localMI`. This merged data structure allows for the integrated visualization of the spatial data with the computed local Moran’s I values, enabling effective geographical analysis of the patterns.

```{r}
hunan.localMI <- cbind(hunan,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

### MAPPING LOCAL MORAN'S I VALUES

Using choropleth mapping functions of the ***tmap*** package, we can plot the local Moran’s I values by using the code chunk below.

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

### MAPPING LOCAL MORAN's I P-VALUES

The choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.

The code chunks below produce a choropleth map of Moran’s I p-values by using functions of **tmap** package.

```{r}
tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

### MAPPING BOTH LOCAL MORAN'S I AND P-VALUES

Let's now plot both the local Moran’s I values and its corresponding p-values next to each other.

```{r}
localMI.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(hunan.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

The left map colors regions based on the value of local Moran's I, with green areas indicating a high positive autocorrelation (values from 3 to 5) suggesting clusters of similar high values, and yellow to orange areas showing lower or negative autocorrelation, indicating less similarity or dispersion. The right map, using shades of blue, shows areas with statistically significant local Moran's I values, with darker blues representing areas with very low p-values (less than 0.001), highlighting regions where the spatial patterns are most pronounced and statistically significant.

# 5. CREATING A *LISA* CLUSTER MAP

The LISA Cluster Map visually represents significant areas, color-coded according to the type of spatial autocorrelation present. Before creating this map, the initial step involves plotting the Moran scatterplot.

## 5.1 Plotting Moran Scatterplot

The Moran Scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

The code chunk below plots the Moran scatterplot of GDPPC 2012 by using `moran.plot()`of ***spdep***.

```{r}
nci <- moran.plot(hunan$GDPPC, rswm_q,
                  labels=as.character(hunan$County), 
                  xlab="GDPPC 2012", 
                  ylab="Spatially Lag GDPPC 2012")
```

The plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. These are the high-high locations.

## 5.2 Plotting Moran Scatterplot with Standardized Variable

First, we'll use the `scale()` function to center and scale the variable. Centering is achieved by subtracting the mean (excluding any NAs) from each value in the column, and scaling involves dividing these centered values by their standard deviations. This standardizes the variable, creating a more uniform scale for analysis.

```{r}
hunan$Z.GDPPC <- scale(hunan$GDPPC) %>% 
  as.vector 
```

Next, `as.vector()` is appended to ensure that the output data type is a vector, which can be easily integrated into our dataframe.

With the data properly prepared and formatted as a vector, we are now set to recreate the Moran scatterplot using the following code chunk. This approach ensures the data is suitable for spatial analysis and visualization in R.

```{r}
nci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,
                   labels=as.character(hunan$County),
                   xlab="z-GDPPC 2012", 
                   ylab="Spatially Lag z-GDPPC 2012")
```

## 5.3 Preparing LISA Map Classes

The code chunks below show the steps to prepare a LISA cluster map.

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Next, we calculate the spatially lagged GDP per capita by taking the weighted average of the GDP per capita from neighboring areas. We then center this lagged value by subtracting its mean, which helps in standardizing the data for analysis.

```{r}
hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     
```

This is followed by centering the local Moran’s around the mean.

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])    
```

Next, let's set a statistical significance level for the local Moran.

```{r}
signif <- 0.05       
```

These four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.

```{r}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4      
```

Lastly, places the non-significant Moran in category 0.

```{r}
quadrant[localMI[,5]>signif] <- 0
```

Actually, all the steps can be combined into one single code chunk as shown below:

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
hunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)
DV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     
LM_I <- localMI[,1]   
signif <- 0.05       
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4    
quadrant[localMI[,5]>signif] <- 0
```

## 5.4 Plotting LISA map

Let's build the LISA map by using the code chunk below.

```{r}
hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

To make for a better interpretation, we can display the local Moran's I values map alongside its corresponding p-values map. This side-by-side layout enhances the analysis by allowing direct visual comparison of spatial autocorrelation with the significance of these patterns.

```{r}
gdppc <- qtm(hunan, "GDPPC")

hunan.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(hunan.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(gdppc, LISAmap, 
             asp=1, ncol=2)
```

> Areas highlighted in red are regions where the GDP per capita is high, and they are also surrounded by other areas with high GDP per capita. Most of the dark orange areas in the GDPPC map correspond to the red regions in the LISA map, reinforcing their status as economically prosperous clusters.

# **6. HOT SPOT AND COLD SPOT AREA ANALYSIS**

Aside from cluster and outlier detection, localized spatial statistics can also be used to detect hot spot and/or cold spot areas.

## 6.1 Getis and Ord’s G-Statistics

An alternative spatial statistic for detecting spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It examines neighbors within a defined proximity to identify where clusters of high or low values occur. Statistically significant hot spots are areas with high values, surrounded by other high-value areas within a certain neighborhood range.

**It consists of three steps:**

1.  **Deriving a spatial weight matrix**
2.  **Computing the Gi statistics**
3.  **Mapping the Gi statistics**

## 6.2 Deriving Distance-Based Weight Matrix

Let's first define a new set of neighbors.

While spatial autocorrelation focused on units that share borders, the Getis-Ord method defines neighbors based on distance.

**There are two types of distance-based proximity matrices:**

1.  **Fixed distance weight matrix**

2.  **Adaptive distance weight matrix**

### DERIVING THE CENTROID MATRIX

Before creating the connectivity graph, we need to assign points to each polygon. This requires more than just applying `st_centroid()` to the `sf` object `us.bound`. We need to extract the coordinates into a separate data frame. To do this, we will use a mapping function, which applies a given function to each element of a vector and returns a vector of the same length.

In this case, the input vector will be the geometry column of `us.bound`, and the function applied will be `st_centroid()`. We will use the `map_dbl` variation from the `purrr` package. For more details, you can refer to the `map` function documentation.

To extract the longitude values, we will map the `st_centroid()` function over the geometry column and access the longitude through double bracket notation `[[]]` with an index of 1. This ensures we capture only the longitude, which is the first value of each centroid.

```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])
```

We do the same for latitude with one key difference. We access the second value per each centroid with \[\[2\]\].

```{r}
latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])
```

Now that we have the latitude and longitude, we use `cbind` to put longitude and latitude into the same object.

```{r}
coords <- cbind(longitude, latitude)
```

### DETERMINE THE CUT-OFF DISTANCE

To determine the upper limit for the distance band, we follow these steps:

1.  **Identify k-nearest neighbors**: Use the `knearneigh()` function from the `spdep` package to generate a matrix that lists the indices of the k-nearest neighbors for each point.

2.  **Convert to neighbors list**: Transform the result from `knearneigh()` into a neighbors list of class `nb`, which contains integer vectors representing neighbor IDs for each region, using `knn2nb()`.

3.  **Calculate neighbor distances**: Use the `nbdists()` function to calculate the distances between neighbors. The distances are returned in the units of the coordinates (or in kilometers if the coordinates are not projected).

4.  **Flatten the structure**: Use `unlist()` to convert the list structure returned by `nbdists()` into a simple vector of distances.

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbor distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbor.

### COMPUTING FIXED DISTANCE WEIGHT MATRIX

Now, we will compute the distance weight matrix by using `dnearneigh()`as shown in the code chunk below.

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

Next, `nb2listw()` is used to convert the ***nb*** object into spatial weights object.

```{r}
wm62_lw <- nb2listw(wm_d62, style = 'B')
summary(wm62_lw)
```

The output spatial weights object is called `wm62_lw`.

### COMPUTING ADAPTIVE DISTANCE WEIGHT MATRIX

One characteristic of a fixed distance weight matrix is that more densely populated areas, typically urban regions, tend to have more neighbors, while less densely populated areas, such as rural counties, have fewer neighbors. Having more neighbors in densely settled areas can result in a smoother relationship across a broader range of neighbors.

You can control the number of neighbors directly by using k-nearest neighbors (k-NN), either allowing for asymmetric neighbor relationships or enforcing symmetry, as demonstrated in the code snippet below. This approach ensures a consistent number of neighbors across different regions, regardless of population density.

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

Next, `nb2listw()` is used to convert the ***nb*** object into spatial weights object.

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

# 7. COMPUTING GI STATISTICS

## 7.1 Gi Statistics Using Fixed Distance

```{r}
fips <- order(hunan$County)
gi.fixed <- localG(hunan$GDPPC, wm62_lw)
gi.fixed
```

The output of the `localG()` function is a vector of G or Gstar values. These values have several attributes: `"gstari"`, which indicates whether Gstar is TRUE or FALSE, `"call"`, which stores the function call, and the class `"localG"`.

The **Gi Statistic** is expressed as a Z-score, where larger values indicate stronger clustering. The direction of the Z-score (positive or negative) shows whether the clustering is of high or low values.

Next, we will associate these Gi values with their respective entries in the `hunan` sf data frame using the following code chunk. This step ensures that each spatial feature is assigned the appropriate **Gi statistic** for further analysis and visualization.

```{r}
hunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

The code chunk mentioned performs three tasks. First, it converts the output vector (`gi.fixed`) into an R matrix object using `as.matrix()`. Next, it uses `cbind()` to combine `hunan@data` and the `gi.fixed` matrix, creating a new `SpatialPolygonDataFrame` called `hunan.gi`. Lastly, the `rename()` function is applied to rename the field containing the Gi values to `gstat_fixed`. This process integrates the Gi statistics into the spatial dataset for further analysis and mapping.

### 7.2 Mapping Gi Values with Fixed Distance Weights

The code chunk below shows the functions used to map the **Gi values** derived using fixed distance weight matrix.

```{r}
gdppc <- qtm(hunan, "GDPPC")

Gimap <-tm_shape(hunan.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, Gimap, asp=1, ncol=2)
```

> The hot spots (in red) were primarily concentrated in the central-eastern part of the region, indicating strong clustering of high GDP per capita values. The cold spots (in blue) were located in the southwestern area, showing regions with low GDP per capita clustering.

The code chunk below is used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e `knb_lw`).

```{r}
fips <- order(hunan$County)
gi.adaptive <- localG(hunan$GDPPC, knn_lw)
hunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

## 7.4 Mapping Gi Values with Adaptive Distance Weights

Now it's time to visualize the hot spot and cold spot areas. We will use the choropleth mapping functions from the `tmap` package to map the Gi values.

The code chunk below demonstrates how to map the Gi values, which were derived using a fixed distance weight matrix. This will allow us to clearly see the spatial distribution of hot and cold spots across the region.

```{r}
gdppc<- qtm(hunan, "GDPPC")

Gimap <- tm_shape(hunan.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(gdppc, 
             Gimap, 
             asp=1, 
             ncol=2)
```

> The hot spot areas (in red) are still concentrated in the same regions as those in the previous map with a fixed distance weight matrix, but the intensity of clustering appears more pronounced. The blue areas (cold spots), have shifted slightly compared to the fixed distance map, with some new cold spots in the southwest.
>
> The adaptive distance weight matrix allows for more flexibility in the number of neighbors, which may lead to a more refined representation of hot and cold spot areas compared to the fixed distance approach.
